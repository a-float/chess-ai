{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0%\n",
      "20.0%\n",
      "30.0%\n",
      "40.0%\n",
      "40.0%\n",
      "40.0%\n",
      "50.0%\n",
      "60.0%\n",
      "60.0%\n",
      "60.0%\n",
      "70.0%\n",
      "70.0%\n",
      "80.0%\n",
      "90.0%\n",
      "100.0%\n",
      "Done in 0.80s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from helpers.utils import parse_dataset\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = os.path.join(\"data\", \"evals.csv\")\n",
    "GAMES_TO_LOAD = 32_000\n",
    "parse_dataset(GAMES_TO_LOAD, DATA_PATH, starts=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.transforms import Compose\n",
    "from helpers.fen import fen_to_bitboard\n",
    "from helpers.data import prepare_chess_frame\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return loss\n",
    "\n",
    "\n",
    "class FenToBits(object):\n",
    "    def __init__(self, merge_colors: bool):\n",
    "        self.merge_colors = merge_colors\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return {\n",
    "            \"eval\": sample[\"eval\"],\n",
    "            \"board\": fen_to_bitboard(sample[\"fen\"], self.merge_colors),\n",
    "        }\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        board, eval = sample[\"board\"], sample[\"eval\"]\n",
    "        return {\n",
    "            \"board\": torch.from_numpy(board).float(),\n",
    "            \"eval\": torch.tensor([eval]).float(),\n",
    "        }\n",
    "\n",
    "\n",
    "class ToTuple(object):\n",
    "    def __call__(self, sample):\n",
    "        return sample[\"board\"], sample[\"eval\"]\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, trial, input_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        activation_f = trial.suggest_categorical(\"activation_func\", [\"sigmoid\", \"relu\", \"tanh\"])\n",
    "        if activation_f == \"sigmoid\":\n",
    "            activation_f = nn.Sigmoid\n",
    "        elif activation_f == \"relu\":\n",
    "            activation_f = nn.ReLU\n",
    "        elif activation_f == \"tanh\":\n",
    "            activation_f = nn.Tanh\n",
    "\n",
    "        conv_layers = trial.suggest_int(\"conv_layers\", 1, 3)\n",
    "        stack = []\n",
    "        in_size = input_shape[0]\n",
    "        kernel = 3\n",
    "        for i in range(conv_layers):\n",
    "            out_size = trial.suggest_int(f\"conv_out_{i+1}\", 2, 128)\n",
    "            l = nn.Conv2d(in_size, out_size, kernel_size=kernel)\n",
    "            in_size = out_size\n",
    "            stack.extend([l, activation_f()])\n",
    "        dense_layers = trial.suggest_int(\"dense_layers\", 1, 3)\n",
    "        stack.append(nn.Flatten())\n",
    "        in_size *= (8 - conv_layers * 2) ** 2\n",
    "        for i in range(dense_layers):\n",
    "            out_size = trial.suggest_int(f\"dense_out_{i+1}\", 4, 128)\n",
    "            dropout = trial.suggest_float(f\"dropout_{i+1}\", 0, 0.5)\n",
    "            l = nn.Linear(in_size, out_size)\n",
    "            in_size = out_size\n",
    "            stack.extend([l, activation_f(), nn.Dropout(dropout)])\n",
    "        stack.append(nn.Linear(in_size, 1))\n",
    "        self.stack = nn.Sequential(*stack)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.df = prepare_chess_frame(df, normalize=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "        sample = {\"fen\": row[\"fen\"], \"eval\": row[\"eval\"]}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:43:49,375] Using an existing study with name 'chess-ai-dropout' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:43:58,005] Trial 133 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:44:06,554] Trial 134 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:44:14,914] Trial 135 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:44:23,303] Trial 136 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:44:31,657] Trial 137 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:44:40,262] Trial 138 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:44:48,596] Trial 139 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:44:56,916] Trial 140 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:45:21,342] Trial 141 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:45:30,022] Trial 142 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:45:52,612] Trial 143 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:46:00,355] Trial 144 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:46:08,120] Trial 145 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:46:15,905] Trial 146 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:47:45,042] Trial 147 finished with value: 0.14128362238407136 and parameters: {'merge_colors': 'False', 'activation_func': 'relu', 'conv_layers': 1, 'conv_out_1': 108, 'dense_layers': 3, 'dense_out_1': 122, 'dropout_1': 0.16845183462902655, 'dense_out_2': 71, 'dropout_2': 0.30326837057087386, 'dense_out_3': 54, 'dropout_3': 0.43426953932282253, 'lr': 0.0007004684993010298, 'optimizer': 'RMSprop'}. Best is trial 147 with value: 0.14128362238407136.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:49:19,835] Trial 148 finished with value: 0.1410828161239624 and parameters: {'merge_colors': 'False', 'activation_func': 'relu', 'conv_layers': 1, 'conv_out_1': 89, 'dense_layers': 2, 'dense_out_1': 124, 'dropout_1': 0.22910426774976667, 'dense_out_2': 59, 'dropout_2': 0.2321420275948466, 'lr': 0.0007271347627868801, 'optimizer': 'Adam'}. Best is trial 148 with value: 0.1410828161239624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:49:28,440] Trial 149 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:50:59,356] Trial 150 finished with value: 0.1554018673300743 and parameters: {'merge_colors': 'False', 'activation_func': 'relu', 'conv_layers': 1, 'conv_out_1': 92, 'dense_layers': 2, 'dense_out_1': 126, 'dropout_1': 0.13714022337190598, 'dense_out_2': 74, 'dropout_2': 0.25752573170156945, 'lr': 0.0007401900227268707, 'optimizer': 'RMSprop'}. Best is trial 148 with value: 0.1410828161239624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:51:07,106] Trial 151 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:51:15,450] Trial 152 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:51:26,307] Trial 153 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:52:53,684] Trial 154 finished with value: 0.1652970325946808 and parameters: {'merge_colors': 'False', 'activation_func': 'relu', 'conv_layers': 1, 'conv_out_1': 99, 'dense_layers': 2, 'dense_out_1': 120, 'dropout_1': 0.12331827684699766, 'dense_out_2': 67, 'dropout_2': 0.2563146870951069, 'lr': 0.0005495014045633169, 'optimizer': 'RMSprop'}. Best is trial 148 with value: 0.1410828161239624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:53:01,360] Trial 155 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:53:31,139] Trial 156 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:53:38,708] Trial 157 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:53:46,390] Trial 158 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:53:54,084] Trial 159 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:54:01,700] Trial 160 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:54:09,357] Trial 161 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 08:54:17,666] Trial 162 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  163\n",
      "  Number of pruned trials:  144\n",
      "  Number of complete trials:  17\n",
      "Best trial:\n",
      "  Value:  0.1410828161239624\n",
      "  Params: \n",
      "    merge_colors: False\n",
      "    activation_func: relu\n",
      "    conv_layers: 1\n",
      "    conv_out_1: 89\n",
      "    dense_layers: 2\n",
      "    dense_out_1: 124\n",
      "    dropout_1: 0.22910426774976667\n",
      "    dense_out_2: 59\n",
      "    dropout_2: 0.2321420275948466\n",
      "    lr: 0.0007271347627868801\n",
      "    optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "def objective(trial):\n",
    "    BATCH_SIZE = 256\n",
    "    print(f\"Running trial {trial.number}\")\n",
    "\n",
    "    merge_colors = trial.suggest_categorical(\"merge_colors\", [\"True\", \"False\"])\n",
    "    chess_dataset = ChessDataset(\n",
    "        csv_file=DATA_PATH,\n",
    "        transform=Compose([FenToBits(merge_colors == \"True\"), ToTensor(), ToTuple()]),\n",
    "    )\n",
    "    train_set, test_set = random_split(chess_dataset, [0.8, 0.2])\n",
    "    train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE)\n",
    "    test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE)\n",
    "\n",
    "    dataset_shape = chess_dataset[0][0].shape\n",
    "    model = NeuralNetwork(trial=trial, input_shape=dataset_shape).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    history = {\"train_loss\": [], \"test_loss\": []}\n",
    "    epochs = 12\n",
    "    for epoch in range(epochs):\n",
    "        # print(f\"Epoch {epoch+1}\\n---------------------\")\n",
    "        train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "\n",
    "        # test\n",
    "        num_batches = len(test_dataloader)\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "        test_loss /= num_batches\n",
    "        trial.report(test_loss, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"test_loss\"].append(test_loss)\n",
    "    return history['test_loss'][-1]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        storage=\"sqlite:///data/db2.sqlite3\",\n",
    "        study_name=\"chess-ai-dropout\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(objective, n_trials=30)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
